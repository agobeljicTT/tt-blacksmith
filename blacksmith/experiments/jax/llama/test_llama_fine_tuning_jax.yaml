# Dataset settings
dataset_id: "stanfordnlp/sst2"

# Model settings
model_name: "Erland/Llama-3.2-1B-JAX"
max_length: 64
dtype: "jnp.float32"

# Training hyperparameters
learning_rate: 1e-4
batch_size: 4
num_epochs: 1
optim: None

# LoRA setup
lora_r: 4
lora_alpha: 8
lora_target_modules: ["mlp.gate_proj.kernel", "mlp.up_proj.kernel", "mlp.down_proj.kernel"]
lora_task_type: "CAUSAL_LM"

# Other settings
use_tt: True
